{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8nYuqu2Drh_H",
    "outputId": "0418ba1c-5da2-4fc7-9f0f-bd5612b85d72"
   },
   "outputs": [],
   "source": [
    "# !pip install shap\n",
    "#!pip install autogluon\n",
    "# !pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UPqpR9G16L5",
    "outputId": "aadfba46-77aa-4354-d7d0-39cdef40fe44"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.impute import KNNImputer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "import re\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import seaborn as sn \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, make_scorer, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import category_encoders as ce\n",
    "\n",
    "pd.set_option('max_rows', 1000)\n",
    "pd.set_option('max_columns', 1000)\n",
    "print(\"Numpy version {}\".format(np.__version__))\n",
    "print(\"Pandas version {}\".format(pd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaYvi7Jm0Efy"
   },
   "outputs": [],
   "source": [
    "cluster_set = pd.read_csv(\"/content/Conflict + Food Insecurity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q9VmLPX80b0E",
    "outputId": "f0140aab-29ba-4018-b3e2-bff87360f8f4"
   },
   "outputs": [],
   "source": [
    "cluster_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvF9m89Y0e0W",
    "outputId": "b685dc61-0590-44b5-d095-e5f78f918f51"
   },
   "outputs": [],
   "source": [
    "# The target variable from clustering\n",
    "cluster_set['clusteringlabels'].isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCpxJavaU8gk"
   },
   "outputs": [],
   "source": [
    "def sklearn_qwk(y_true, y_pred) -> np.float64:\n",
    "    \"\"\"\n",
    "    Function for measuring Quadratic Weighted Kappa with scikit-learn\n",
    "    \n",
    "    :param y_true: The ground truth labels\n",
    "    :param y_pred: The predicted labels\n",
    "    \n",
    "    :return The Quadratic Weighted Kappa Score (QWK)\n",
    "    \"\"\"\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3ZZVcEcr0pY"
   },
   "outputs": [],
   "source": [
    "# path to data file\n",
    "path = \"/content/2020_22_cleaned.csv\"\n",
    "\n",
    "df = pd.read_csv(path, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33_s0KY34dXH"
   },
   "outputs": [],
   "source": [
    "# The cluster labels are in the same order as the dataset is\n",
    "# therefore, we can directly get the target column from the cluster dataset\n",
    "df['target'] = cluster_set['clusteringlabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BYkBj5Q4nVl",
    "outputId": "bb1a3c12-ab3e-41b7-ff64-f009926c5386"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "wBGrritnzXJJ",
    "outputId": "4109fede-6da0-4555-d3db-b5cdd8add1a2"
   },
   "outputs": [],
   "source": [
    "df.replace(\"à\", 'a', regex=True, inplace=True)\n",
    "df.replace(\"à\", 'a', regex=True, inplace=True)\n",
    "df.replace(\"è\", 'e', regex=True, inplace=True)\n",
    "df.replace(\"é\", 'e', regex=True, inplace=True)\n",
    "df.replace(\"ï\", 'i', regex=True, inplace=True)\n",
    "df[df['admin1']=='menaka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "v2fwbs0bzbkJ",
    "outputId": "256be815-e611-4d6c-ec88-8dd70ecd2bf9"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5CU5n2Wm3pA"
   },
   "outputs": [],
   "source": [
    "# filling out the from 'human' column from Hotspot Analysis with 'Human' data from INFORM model\n",
    "#df['human'].fillna(df['Human'], inplace=True)\n",
    "\n",
    "# removing all the burden data\n",
    "to_drop = ['GAM_Burden_R_rest', 'SAM_Burden_R_rest', 'MAM_Burden_R_rest', 'gam_burden', 'sam_burden', 'mam_burden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "MuC8Pzjbzigh",
    "outputId": "1c84fd95-16bb-4f58-9d53-e4ef38825f04"
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sA31f4mKa1WX"
   },
   "outputs": [],
   "source": [
    "df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYsdnV0R5HBI",
    "outputId": "c90b5533-e8ef-46c0-cd5a-b1169eee142d"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "id": "KcXARN_vsOSd",
    "outputId": "c2a88a70-08de-41ac-eee9-1f8065d58fff"
   },
   "outputs": [],
   "source": [
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZPvA_uf49DE",
    "outputId": "27bd132c-bb17-46c2-c3e0-7f7a3fc3cee5"
   },
   "outputs": [],
   "source": [
    "# checking the columns having object data type 'x'\n",
    "df['Food_Insecurity_Probability'].values\n",
    "\n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "print([x for x in df['Food_Insecurity_Probability'].values if is_float(x) == False])\n",
    "print([x for x in df['Food_Security'].values if is_float(x) == False])\n",
    "print([x for x in df['Mortality_rate_under-5'].values if is_float(x) == False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUxmfUVMrQx1"
   },
   "outputs": [],
   "source": [
    "# replacing 'x' by np.NaN\n",
    "df.loc[df['Food_Insecurity_Probability'] == 'x', 'Food_Insecurity_Probability'] = np.NaN\n",
    "df.loc[df['Food_Security'] == 'x', 'Food_Security'] = np.NaN\n",
    "df.loc[df['Mortality_rate_under-5'] == 'x', 'Mortality_rate_under-5'] = np.NaN\n",
    "\n",
    "df['Food_Insecurity_Probability'] = df['Food_Insecurity_Probability'].astype(float)\n",
    "df['Food_Security'] = df['Food_Security'].astype(float)\n",
    "df['Mortality_rate_under-5'] = df['Mortality_rate_under-5'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-V5KE3FIvtGj"
   },
   "outputs": [],
   "source": [
    "# removing the categorical columns with a lot categories\n",
    "#to_drop = ['ADMIN_2_Admnistratif', \t'admin2_sanitary', 'DS_ADMIN_2_Admnistratif_Burden_Data']\n",
    "\n",
    "#df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "F4QxPhA9sC50",
    "outputId": "33e477a4-c729-4e62-faf6-b9e0f8463110"
   },
   "outputs": [],
   "source": [
    "# checking integer columns\n",
    "df.describe(include=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BowkzlEmT3V2"
   },
   "outputs": [],
   "source": [
    "# comparing the 50/ 75/ max values in the above table\n",
    "\n",
    "cols_for_transformation = ['population_totale', 'population_6-59_month',\t'mam_6-59_mois_prevalence', 'idps', 'Population_sans_acces_aux_structures_de_sante']\n",
    "\n",
    "for col in cols_for_transformation:\n",
    "  df[col] = np.log(df[col]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6k9BX3wj5E4m",
    "outputId": "107f0c75-8687-473d-ae21-1bf5dce5b156"
   },
   "outputs": [],
   "source": [
    "# Removing the columns having more than 70% missing values\n",
    "print(df.shape)\n",
    "df.drop(df.columns[df.isnull().sum(axis=0)/ df.shape[0] > 0.7], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBVxFLrn0rVp",
    "outputId": "2f37d0b9-fc77-4d98-8e33-79951e7198b8"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tU_ixFoQ1mB_",
    "outputId": "25a1ce33-650a-472b-a5bc-b84f96ad36de"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsUKnyEP1sCr"
   },
   "outputs": [],
   "source": [
    "target_column = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5frdpJeU5ONH",
    "outputId": "c9ac5dcd-dd62-4417-83cf-465fb521e286"
   },
   "outputs": [],
   "source": [
    "# target column has 14 missing values out of total 1102 values. Checking year wise split and removing those 14 rows\n",
    "df['target_null'] = df[target_column].isnull()\n",
    "\n",
    "print(df.groupby('year')['target_null'].count())\n",
    "\n",
    "print(df.groupby('year')['target_null'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k55gf4Jsm5TT"
   },
   "outputs": [],
   "source": [
    "df = df.loc[df[target_column].isnull()==False, :]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.drop('target_null', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1Ol_ZbV6vEg"
   },
   "outputs": [],
   "source": [
    "# seeing region wise distribution in different years\n",
    "area_distribution = df.groupby(['year', 'admin1'])['priority_level_validated_by_the_clusters'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 950
    },
    "id": "wUaaKKA3_Rak",
    "outputId": "f421dbc3-6db1-4077-9068-898ee608fbc8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,year in enumerate(area_distribution['year'].unique()):\n",
    "  data = area_distribution.loc[area_distribution['year'] == year, :]\n",
    "  print(\"Number of unique admin regions {}\".format(len(data['admin1'].unique())))\n",
    "  print(sorted(data['admin1'].unique()))\n",
    "  data.reset_index(drop=True, inplace=True)\n",
    "  data.sort_values(by='priority_level_validated_by_the_clusters', inplace=True, ascending=False)\n",
    "  plt.figure(figsize=(40,10))\n",
    "  plt.bar(data['admin1'], data['priority_level_validated_by_the_clusters'])\n",
    "  plt.xticks(rotation=45)\n",
    "  plt.xlabel('admin1')\n",
    "  plt.ylabel('Number of rows for {}'.format(year))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGmNhiXk1C-6",
    "outputId": "ca3eab39-88f0-4b9e-a0fb-c82fb15804ac"
   },
   "outputs": [],
   "source": [
    "#Dropping priority level validated by clusters & DS_ADMIN_2_Admnistratif_Burden_Data\n",
    "df.drop(['DS_ADMIN_2_Admnistratif_Burden_Data'], axis=1, inplace=True)\n",
    "df.drop(['priority_level_validated_by_the_clusters'], axis=1, inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AW8UrgAB0nO"
   },
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "numerical_columns = []\n",
    "\n",
    "for col in df.columns:\n",
    "  if col != 'year':\n",
    "    if df[col].dtype == object:\n",
    "      categorical_columns.append(col)\n",
    "    elif df[col].dtype == 'float64':\n",
    "      numerical_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJRLnlFjhibV",
    "outputId": "81ab9e49-f0a7-4f57-af72-d45f62b0db6a"
   },
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62Vbw-p9TFFW",
    "outputId": "b6aa5901-a17c-43ba-9cd6-3062837f8ac7"
   },
   "outputs": [],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5S6ogRWi4Bc",
    "outputId": "42e156fc-aba7-46de-fa0b-1d0f3a3184e1"
   },
   "outputs": [],
   "source": [
    "# encoding categorical columns to numerical columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl = LabelEncoder()\n",
    "\n",
    "for var in categorical_columns:\n",
    "    df[var] = lbl.fit_transform(df[var])\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "id": "7HN3WeipTG1-",
    "outputId": "5ae8e7ea-c9cb-44fe-9b1b-1806d653fa08"
   },
   "outputs": [],
   "source": [
    "# exploring correlation amongst columns having numerical values \n",
    "corr = df[numerical_columns].corr()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(60)\n",
    "fig.set_figwidth(60)\n",
    "sns.heatmap(df.corr(method='pearson'), annot=True, fmt='.4f', \n",
    "            cmap=plt.get_cmap('coolwarm'), cbar=False, ax=ax)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=\"horizontal\")\n",
    "fig.savefig(\"out.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rL_aB5eUTOuR",
    "outputId": "bdff1076-48e7-43f7-faa6-9468e5e4e0b7"
   },
   "outputs": [],
   "source": [
    "# dropping features with correlation greater than 0.9 \n",
    "corr = df[numerical_columns].corr().abs()\n",
    "\n",
    "corr_cut_off = 0.9\n",
    "\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > corr_cut_off)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZ-qB0ieVVmA",
    "outputId": "623ab86f-e29f-4eaf-db47-5d3732839414"
   },
   "outputs": [],
   "source": [
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIEUodlumBL1"
   },
   "outputs": [],
   "source": [
    "df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqeO9uy3lmXJ",
    "outputId": "6a85b76c-e274-4e05-ba5a-618bc116f99d"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2X68Y3eKiGj1",
    "outputId": "d4f57054-6a9e-4ada-d7d3-a10e99ad41fe"
   },
   "outputs": [],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCpwBtGHiP5F",
    "outputId": "07feb80d-d6cb-4cc5-9822-2e0a52bdbcef"
   },
   "outputs": [],
   "source": [
    "df.groupby('year')['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30P7PRw4cNZA"
   },
   "outputs": [],
   "source": [
    "# feature 'year' used for splitting the data into train test\n",
    "target_column = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "d_JNaa-sdF0H",
    "outputId": "00865538-757e-4186-ded4-32d90fe0e9b0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[target_column].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "cVlqaRpN19rm",
    "outputId": "058b7400-b169-4b37-f0b4-6eae05829371"
   },
   "outputs": [],
   "source": [
    "df.groupby('year')['target'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ef0OCVPlqIY"
   },
   "outputs": [],
   "source": [
    "# splitting the set into train and test set using the 'year'\n",
    "train = df.loc[df['year'] != 2022, :].reset_index(drop=True)\n",
    "test = df.loc[df['year'] == 2022, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAvvJYr_p9nn"
   },
   "outputs": [],
   "source": [
    "# removing the 'year' from the dataset (will lead to overfitting during training)\n",
    "train.drop('year', axis=1, inplace=True)\n",
    "test.drop('year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kJL61zwpgyo"
   },
   "outputs": [],
   "source": [
    "xtrain = train.loc[:, train.columns != 'target']\n",
    "ytrain = train['target']\n",
    "xtest = test.loc[:, train.columns != 'target']\n",
    "ytest = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzXeIduovdGu"
   },
   "outputs": [],
   "source": [
    "# qwk metric for calculating divergence regarding actual labels\n",
    "def sklearn_qwk(y_true, y_pred) -> np.float64:\n",
    "    \"\"\"\n",
    "    Function for measuring Quadratic Weighted Kappa with scikit-learn\n",
    "    \n",
    "    :param y_true: The ground truth labels\n",
    "    :param y_pred: The predicted labels\n",
    "    \n",
    "    :return The Quadratic Weighted Kappa Score (QWK)\n",
    "    \"\"\"\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pa3FWJ9i21mT"
   },
   "outputs": [],
   "source": [
    "def one_away_accuracy(y_true, y_pred) -> np.float64:\n",
    "    \"\"\"\n",
    "    Function for measuring 1-away-accuracy with scikit-learn\n",
    "    \n",
    "    :param y_true: The ground truth labels\n",
    "    :param y_pred: The predicted labels\n",
    "    \n",
    "    :return 1_away_accuracy (1_accuracy)\n",
    "    \"\"\"\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    #df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    "\n",
    "    to_sum_list = []\n",
    "    \n",
    "    for i in range(cmx_data.shape[0]):\n",
    "        to_sum_list.append(cmx_data[i][i])\n",
    "\n",
    "    for i in range(1, cmx_data.shape[0]):\n",
    "        to_sum_list.append(cmx_data[i][i - 1])\n",
    "        to_sum_list.append(cmx_data[i-1][i])\n",
    "    \n",
    "    one_away_acc = sum(to_sum_list)/sum(np.concatenate(cmx_data))\n",
    "    return one_away_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmMRbav32JBu"
   },
   "outputs": [],
   "source": [
    "kappa_scorer = make_scorer(sklearn_qwk)\n",
    "one_acc_scorer = make_scorer(one_away_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Oa26_IT406X"
   },
   "outputs": [],
   "source": [
    "# plotting confusion matrix\n",
    "def print_cmx(y_true, y_pred, label):\n",
    "    print(\"Confusion Matrix: {}\".format(label))\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sn.heatmap(df_cmx, annot=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8XIHCHU1u7o"
   },
   "outputs": [],
   "source": [
    "model_outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ca6t2er2pvAr"
   },
   "outputs": [],
   "source": [
    "# random forest parameter optimization\n",
    "# since KNN is a distance based algorithm we'll scale the features and then use imputation to fill the values.\n",
    "# creating a pipeline for all the algorithms\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('impute', KNNImputer(n_neighbors=3)),\n",
    "    ('rf', RandomForestClassifier(random_state=2021, n_estimators=200))\n",
    "])\n",
    "\n",
    "# we have a list of possible values for each hyperparameter\n",
    "params= { \n",
    "    'rf__max_features': ['auto', 'sqrt'],\n",
    "    'rf__max_depth' : [4,5,6,8],\n",
    "    'rf__min_samples_split': [2,5,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJro0FmRBNmV"
   },
   "outputs": [],
   "source": [
    "feat = [x for x in xtrain.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 944
    },
    "id": "LrVWhiQm1mFk",
    "outputId": "dea2fbdd-1eb6-4b25-ad5f-5b11ffac996a"
   },
   "outputs": [],
   "source": [
    "# 10-fold cross validation is used for hyperparameter tuning; \n",
    "# creating RF only on accuracy score as others (one_away and QWK) should not affect much\n",
    "\n",
    "clf = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "clf.fit(xtrain[feat], ytrain)\n",
    "\n",
    "score = cross_val_score(clf.best_estimator_, xtrain[feat], ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "# saving the best model for RandomForest for stacking\n",
    "model_rf = clf.best_estimator_\n",
    "\n",
    "model_rf.fit(xtrain[feat], ytrain)\n",
    "\n",
    "pred = clf.best_estimator_.predict(xtest[feat])\n",
    "\n",
    "print(\"Classification Report for the test set with Accuracy as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print(model_rf)\n",
    "\n",
    "print_cmx(ytest, pred, \"Accuracy as Metric\")\n",
    "\n",
    "#Storing All 3 results for each algo\n",
    "acc = accuracy_score(ytest, pred)\n",
    "qwk = sklearn_qwk(ytest, pred)\n",
    "one_away_acc = one_away_accuracy(ytest, pred)\n",
    "\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"RandomForest\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6oYdskIfukfR",
    "outputId": "7001caa8-b358-4e4a-80ee-b7b8b48e571e"
   },
   "outputs": [],
   "source": [
    "# SHAP values are calculated for each class individually - Accuracy\n",
    "explainer = shap.TreeExplainer(model_rf['rf'])\n",
    "shap_values = np.array(explainer.shap_values(xtrain[feat]))\n",
    "\n",
    "\n",
    "# feature importance for class i for loop\n",
    "for i in range(4):\n",
    "    print(\"****** Feature importances for class \" + str(i) +\" ******\")\n",
    "    shap.summary_plot(shap_values[i], xtrain[feat], plot_type=\"bar\")\n",
    "    shap.summary_plot(shap_values[i], features=xtrain[feat], feature_names=feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lIT9_JvE7bQC",
    "outputId": "89d6e969-0832-4782-b81f-d3b92c594e83"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 2\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[2], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-KemezCi7Sj4",
    "outputId": "09f025a6-8d77-4516-d2af-b37078e8c684"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 1\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[1], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eA_F8BB_Ggqu",
    "outputId": "bbb63f5a-6a67-423b-cb43-cb53cae7a7cd"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 3\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[3], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "t20Q_skPGkAd",
    "outputId": "06c29109-990b-4894-8760-664a9395c526"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 0\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[0], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "id": "Udx8QP0a900g",
    "outputId": "b9098b3e-9ac7-4db2-83d5-75fc00f1cc73"
   },
   "outputs": [],
   "source": [
    "#Normal Feature Importance: Choose a value of top k and dispaly top_k features of the model\n",
    "\n",
    "top_k = 15\n",
    "\n",
    "importances = pd.DataFrame()\n",
    "importances ['feature'] = feat\n",
    "importances ['feature_imp'] = clf.best_estimator_.named_steps[\"rf\"].feature_importances_\n",
    "\n",
    "print(\"Feature_Imp\")\n",
    "\n",
    "plt.figure(figsize = (8, 12))\n",
    "sns.barplot(x = 'feature_imp', y = 'feature', data=importances.sort_values('feature_imp', ascending=False).head(top_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eaw-TwY1259J"
   },
   "outputs": [],
   "source": [
    "# lightgbm hyperparameter tuning\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('impute', KNNImputer(n_neighbors=3)),\n",
    "    ('lgb', lgb.LGBMClassifier(random_state=2021, n_estimators=200))\n",
    "])\n",
    "\n",
    "params = {'lgb__max_depth': [4, 6, 8],\n",
    "                   'lgb__num_leaves': [16, 32],\n",
    "                   'lgb__colsample_bytree': [0.65, 0.75, 0.9], \n",
    "                   'lgb__subsample': [0.7, 0.8, 0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LRZP03VALNl3",
    "outputId": "7b4dee55-ac41-4a29-a56c-38ef2d961a63"
   },
   "outputs": [],
   "source": [
    "# Making two Lgb models; 1 which does parameter tuning on accuracy other on QWK; Store 3 metrics for both.\n",
    "\n",
    "# 10 fold cross validation is used for hyperparameter tuning using accuracy\n",
    "\n",
    "clf_acc = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "clf_acc.fit(xtrain[feat], ytrain)\n",
    "\n",
    "score = cross_val_score(clf_acc.best_estimator_, xtrain[feat], ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "model_lgb_acc = clf_acc.best_estimator_\n",
    "\n",
    "model_lgb_acc.fit(xtrain[feat], ytrain)\n",
    "\n",
    "pred = clf_acc.best_estimator_.predict(xtest[feat])\n",
    "\n",
    "print(\"Classification Report for the test set with Accuracy as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print_cmx(ytest, pred, \"Accuracy as Metric\")\n",
    "\n",
    "acc = accuracy_score(ytest, pred)\n",
    "qwk = sklearn_qwk(ytest, pred)\n",
    "one_away_acc = one_away_accuracy(ytest, pred)\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"LightGBM_acc\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})\n",
    "\n",
    "# 10 fold cross validation is used for hyperparameter tuning using QWK\n",
    "clf_qwk = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring=kappa_scorer)\n",
    "\n",
    "clf_qwk.fit(xtrain[feat], ytrain)\n",
    "\n",
    "score_qwk = cross_val_score(clf_qwk.best_estimator_, xtrain[feat], ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "model_lgb_qwk = clf_qwk.best_estimator_\n",
    "\n",
    "model_lgb_qwk.fit(xtrain[feat], ytrain)\n",
    "\n",
    "pred = clf_qwk.best_estimator_.predict(xtest[feat])\n",
    "\n",
    "print(\"Classification Report for the test set with QWK as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print_cmx(ytest, pred, \"QWK as Metric\")\n",
    "\n",
    "acc = accuracy_score(ytest, pred)\n",
    "qwk = sklearn_qwk(ytest, pred)\n",
    "one_away_acc = one_away_accuracy(ytest, pred)\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"LightGBM_qwk\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCVd0o6M-uma",
    "outputId": "1754a3f6-7ff9-459f-c448-1f952ff7d5de"
   },
   "outputs": [],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzZdAjuYKhVa"
   },
   "outputs": [],
   "source": [
    "# using an additional step to use lightgbm's inbuilt capacility to handle missing values\n",
    "pipe = Pipeline(steps=[\n",
    "    ('lgb', lgb.LGBMClassifier(random_state=2021, n_estimators=200))\n",
    "])\n",
    "\n",
    "params = {'lgb__max_depth': [4, 6, 8],\n",
    "                   'lgb__num_leaves': [16, 32],\n",
    "                   'lgb__colsample_bytree': [0.65, 0.75, 0.9], \n",
    "                   'lgb__subsample': [0.7, 0.8, 0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NjMs9yu8LNl4",
    "outputId": "cf53fa49-d6ba-41ea-e804-81196908e28b"
   },
   "outputs": [],
   "source": [
    "# 10 fold cross validation is used for hyperparameter tuning with accuracy\n",
    "clf = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "score = cross_val_score(clf.best_estimator_, xtrain, ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "model_lgb_noimp = clf.best_estimator_\n",
    "\n",
    "model_lgb_noimp.fit(xtrain, ytrain)\n",
    "\n",
    "pred = clf.best_estimator_.predict(xtest)\n",
    "\n",
    "print(\"Classification Report for the test set with Accuracy as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print_cmx(ytest, pred, \"Accuracy as Metric\")\n",
    "\n",
    "acc = accuracy_score(ytest, pred)\n",
    "qwk = sklearn_qwk(ytest, pred)\n",
    "one_away_acc = one_away_accuracy(ytest, pred)\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"LightGBM_no_imputation_acc\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})\n",
    "\n",
    "# 10fold cross validation is used for hyperparameter tuning with QWK\n",
    "clf = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring=kappa_scorer)\n",
    "\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "score_qwk = cross_val_score(clf.best_estimator_, xtrain, ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "model_lgb_qwk_noimp = clf.best_estimator_\n",
    "\n",
    "model_lgb_qwk_noimp.fit(xtrain, ytrain)\n",
    "\n",
    "pred = clf.best_estimator_.predict(xtest)\n",
    "\n",
    "print(\"Classification Report for the test set with QWK as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print_cmx(ytest, pred, \"QWK as Metric\")\n",
    "\n",
    "acc = accuracy_score(ytest, pred)\n",
    "qwk = sklearn_qwk(ytest, pred)\n",
    "one_away_acc = one_away_accuracy(ytest, pred)\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"LightGBM_no_imputation_qwk\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "AFU8F1pX_LeU",
    "outputId": "1ba23396-460c-406a-a484-58bad80b359f"
   },
   "outputs": [],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9svOof_VJPb-",
    "outputId": "c8689f5d-b952-4fee-dd57-57c4def0451d"
   },
   "outputs": [],
   "source": [
    "# SHAP values are calculated for each class individually\n",
    "explainer = shap.TreeExplainer(model_lgb_noimp['lgb'])\n",
    "\n",
    "shap_values = np.array(explainer.shap_values(xtrain))\n",
    "\n",
    "# feature importance for class i for loop\n",
    "for i in range(4):\n",
    "    print(\"****** Feature importances for class \" + str(i) +\" ******\")\n",
    "    shap.summary_plot(shap_values[i], xtrain[feat], plot_type=\"bar\")\n",
    "    shap.summary_plot(shap_values[i], features=xtrain[feat], feature_names=feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3VGLeuLe_T80",
    "outputId": "ddfd7a5f-9f3a-4504-d139-48d34ecc3621"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 0\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[0], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kUFn5JTF_UQ8",
    "outputId": "c8698e21-8a98-4893-80c5-c89f9942b384"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 1\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[1], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zLfpKdjzHuQn",
    "outputId": "8ce78121-21d9-471a-b310-8bb42701b51e"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 2\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[2], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6yNDYECeHuca",
    "outputId": "181f5d7e-1e98-4b0c-e185-e4d1823b5a8e"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 3\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[3], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZeRaVrGv59yp",
    "outputId": "782fdfac-6f04-4da9-c40d-375f34d7c4b8"
   },
   "outputs": [],
   "source": [
    "#Normal Feature Importance: Choose a value of top k and dispaly top_k features of the model\n",
    "\n",
    "top_k = 15\n",
    "\n",
    "importances = pd.DataFrame()\n",
    "importances ['feature'] = feat\n",
    "importances ['feature_imp'] = clf.best_estimator_.named_steps[\"lgb\"].feature_importances_\n",
    "\n",
    "print(\"Feature_Imp\")\n",
    "\n",
    "plt.figure(figsize = (8, 12))\n",
    "sns.barplot(x = 'feature_imp', y = 'feature', data=importances.sort_values('feature_imp', ascending=False).head(top_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BwW2b6w62uEU"
   },
   "outputs": [],
   "source": [
    "# xgboost hyperparameter tuning\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('impute', KNNImputer(n_neighbors=3)),\n",
    "    ('xgb', xgb.XGBClassifier(random_state=2021, n_estimators=200, min_child_weight=3, use_label_encoder=True, eval_metric='mlogloss'))\n",
    "])\n",
    "\n",
    "params =  {\n",
    "        'xgb__max_depth': [3, 5, 8],\n",
    "        'xgb__subsample': [0.5, 0.7, 0.9],\n",
    "        'xgb__colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "tDkLCwYULnEL",
    "outputId": "ab6c3c34-1ad2-4889-dd65-7a64ef434b7b"
   },
   "outputs": [],
   "source": [
    "ytrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XlOPeTQoLNl6",
    "outputId": "caf5896a-c921-4cea-b05a-faec56f6bd19"
   },
   "outputs": [],
   "source": [
    "# 10 fold cross validation is used for hyperparameter tuning with accuracy\n",
    "clf = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "score = cross_val_score(clf.best_estimator_, xtrain, ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "model_xgb = clf.best_estimator_\n",
    "\n",
    "model_xgb.fit(xtrain, ytrain)\n",
    "\n",
    "pred = clf.best_estimator_.predict(xtest)\n",
    "\n",
    "print(\"Classification Report for the test set with Accuracy as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print_cmx(ytest, pred, \"Accuracy as Metric\")\n",
    "\n",
    "acc = accuracy_score(ytest, pred)\n",
    "qwk = sklearn_qwk(ytest, pred)\n",
    "one_away_acc = one_away_accuracy(ytest, pred)\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"XGBoost_acc\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})\n",
    "\n",
    "# 10fold cross validation is used for hyperparameter tuning with QWK\n",
    "clf = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring=kappa_scorer)\n",
    "\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "score_qwk = cross_val_score(clf.best_estimator_, xtrain, ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "model_xgb_qwk = clf.best_estimator_\n",
    "\n",
    "model_xgb_qwk.fit(xtrain, ytrain)\n",
    "\n",
    "pred = clf.best_estimator_.predict(xtest)\n",
    "\n",
    "print(\"Classification Report for the test set with QWK as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print_cmx(ytest, pred, \"QWK as Metric\")\n",
    "\n",
    "acc_qwk = accuracy_score(ytest, pred)\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"XGBoost_qwk\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZjSEkF1U_6SN",
    "outputId": "d7efc7f3-24ee-4c92-c283-42db12d3a768"
   },
   "outputs": [],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TCTrv7EBNavH"
   },
   "outputs": [],
   "source": [
    "# xgboost hyperparameter tuning\n",
    "pipe = Pipeline(steps=[\n",
    "  ('xgb', xgb.XGBClassifier(random_state=2021, n_estimators=200, min_child_weight=3, use_label_encoder=True, eval_metric='mlogloss'))\n",
    "])\n",
    "\n",
    "params =  {\n",
    "        'xgb__max_depth': [3, 5, 8],\n",
    "        'xgb__subsample': [0.5, 0.7, 0.9],\n",
    "        'xgb__colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "rBMQ_IynLNl8",
    "outputId": "7ac5f272-e4c9-404b-f341-95f8fdb35220"
   },
   "outputs": [],
   "source": [
    "# 10 fold cross validation is used for hyperparameter tuning\n",
    "clf = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "score = cross_val_score(clf.best_estimator_, xtrain, ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "model_xgb_noimp = clf.best_estimator_\n",
    "\n",
    "model_xgb_noimp.fit(xtrain, ytrain)\n",
    "\n",
    "pred = clf.best_estimator_.predict(xtest)\n",
    "\n",
    "print(\"Classification Report for the test set with Accuracy as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print_cmx(ytest, pred, \"Accuracy as Metric\")\n",
    "\n",
    "acc = accuracy_score(ytest, pred)\n",
    "qwk = sklearn_qwk(ytest, pred)\n",
    "one_away_acc = one_away_accuracy(ytest, pred)\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"XGBoost_no_imputation_acc\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})\n",
    "\n",
    "# 10fold cross validation is used for hyperparameter tuning\n",
    "clf = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring=kappa_scorer)\n",
    "\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "score_qwk = cross_val_score(clf.best_estimator_, xtrain, ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "model_xgb_qwk_noimp = clf.best_estimator_\n",
    "\n",
    "model_xgb_qwk_noimp.fit(xtrain, ytrain)\n",
    "\n",
    "pred = clf.best_estimator_.predict(xtest)\n",
    "\n",
    "print(\"Classification Report for the test set with QWK as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print_cmx(ytest, pred, \"QWK as Metric\")\n",
    "\n",
    "acc = accuracy_score(ytest, pred)\n",
    "qwk = sklearn_qwk(ytest, pred)\n",
    "one_away_acc = one_away_accuracy(ytest, pred)\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"XGBoost_no_imputation_qwk\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Va2rOfN2AL2M",
    "outputId": "e1a845a4-e0ed-422f-c6a9-c7307077c234"
   },
   "outputs": [],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_i-NiIZnRHBQ",
    "outputId": "61beb6ff-9611-4489-e06c-989ffde03d69"
   },
   "outputs": [],
   "source": [
    "# SHAP values are calculated for each class individually\n",
    "explainer = shap.TreeExplainer(model_xgb_noimp['xgb'])\n",
    "\n",
    "shap_values = np.array(explainer.shap_values(xtrain))\n",
    "\n",
    "# feature importance for class i for loop\n",
    "for i in range(4):\n",
    "    print(\"****** Feature importances for class \" + str(i) +\" ******\")\n",
    "    shap.summary_plot(shap_values[i], xtrain[feat], plot_type=\"bar\")\n",
    "    shap.summary_plot(shap_values[i], features=xtrain[feat], feature_names=feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4fjYb0f8ATO4",
    "outputId": "fdbe2c59-180c-4453-9a3d-481ee23664a4"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 0\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[0], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "pUGYlWE0ATf5",
    "outputId": "1181cac9-6e7d-42cf-aad7-fe82c63750ea"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 1\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[1], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zN9dHdXnInrc",
    "outputId": "87d17f66-df51-45e3-9582-386454354a6c"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 2\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[2], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "DqzzJ499InzH",
    "outputId": "18b82a1f-a653-4001-c526-37e4fd18f056"
   },
   "outputs": [],
   "source": [
    "# make dependency plots of all the features for class 3\n",
    "for i in range(len(feat)):\n",
    "    shap.dependence_plot(i, shap_values[3], xtrain[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NwGtJLMg7Blo",
    "outputId": "7e460158-c998-4ddd-837c-722a3145ef77"
   },
   "outputs": [],
   "source": [
    "#Normal Feature Importance: Choose a value of top k and dispaly top_k features of the model\n",
    "\n",
    "top_k = 15\n",
    "\n",
    "importances = pd.DataFrame()\n",
    "importances ['feature'] = feat\n",
    "importances ['feature_imp'] = clf.best_estimator_.named_steps[\"xgb\"].feature_importances_\n",
    "\n",
    "print(\"Feature_Imp\")\n",
    "\n",
    "plt.figure(figsize = (8, 12))\n",
    "sns.barplot(x = 'feature_imp', y = 'feature', data=importances.sort_values('feature_imp', ascending=False).head(top_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "u7V77w2kRJ1X"
   },
   "outputs": [],
   "source": [
    "# for svm model we need to scale the numerical column - se define a pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('impute', KNNImputer(n_neighbors=3)),\n",
    "    ('svm', SVC(random_state=2021))\n",
    "])\n",
    "\n",
    "# defining parameter grid for finding the optimal C value using the training data\n",
    "params = {'svm__C':[0.01, 10, 100, 1000, 2500, 5000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "i8RKYMOKLNl9",
    "outputId": "1044e243-776e-4278-e5d7-7b93276639d5"
   },
   "outputs": [],
   "source": [
    "# 10 fold cross validation is used for hyperparameter tuning\n",
    "clf = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "score = cross_val_score(clf.best_estimator_, xtrain, ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "model_svm = clf.best_estimator_\n",
    "\n",
    "model_svm.fit(xtrain, ytrain)\n",
    "\n",
    "pred = clf.best_estimator_.predict(xtest)\n",
    "\n",
    "print(\"Classification Report for the test set with Accuracy as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print_cmx(ytest, pred, \"Accuracy as Metric\")\n",
    "\n",
    "acc = accuracy_score(ytest, pred)\n",
    "qwk = sklearn_qwk(ytest, pred)\n",
    "one_away_acc = one_away_accuracy(ytest, pred)\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"SVC_acc\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})\n",
    "\n",
    "# 10fold cross validation is used for hyperparameter tuning\n",
    "clf = GridSearchCV(pipe, params, cv=10, n_jobs=-1, scoring=kappa_scorer)\n",
    "\n",
    "clf.fit(xtrain, ytrain)\n",
    "\n",
    "score_qwk = cross_val_score(clf.best_estimator_, xtrain, ytrain, cv=10, scoring='accuracy')\n",
    "\n",
    "model_svm_qwk = clf.best_estimator_\n",
    "\n",
    "model_svm_qwk.fit(xtrain, ytrain)\n",
    "\n",
    "pred = clf.best_estimator_.predict(xtest)\n",
    "\n",
    "print(\"Classification Report for the test set with QWK as metric {}\".format(classification_report(ytest, pred)))\n",
    "\n",
    "print_cmx(ytest, pred, \"QWK as Metric\")\n",
    "\n",
    "acc = accuracy_score(ytest, pred)\n",
    "qwk = sklearn_qwk(ytest, pred)\n",
    "one_away_acc = one_away_accuracy(ytest, pred)\n",
    "\n",
    "model_outputs.append({\n",
    "    'model': \"SVC_qwk\",\n",
    "    'cv_score_mean': score.mean(),\n",
    "    'cv_score_std': score.std(),\n",
    "    'test_accuracy': acc,\n",
    "    'test_qwk': qwk,\n",
    "    'test_one_away': one_away_acc\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XETfoHtUAorD",
    "outputId": "b0495b3d-dfc1-4c59-d6ff-422602e5d11c"
   },
   "outputs": [],
   "source": [
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "referenced_widgets": [
      "69115f80896d47eda6a218751d1d3eed"
     ]
    },
    "id": "hgbF3D7c4uXZ",
    "outputId": "07490b7c-3099-47d2-e3ea-7a59e2706803"
   },
   "outputs": [],
   "source": [
    "# svm explainer for SHAP values\n",
    "svm_explainer = shap.KernelExplainer(model_svm.predict,xtest.iloc[0:20])\n",
    "svm_shap_values = svm_explainer.shap_values(xtest.iloc[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "QZwEOkMX4x1s",
    "outputId": "bf94e9c0-a369-4896-f8dd-eb1f70770f2e"
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(svm_shap_values, xtest.iloc[0:20], plot_type=\"bar\")\n",
    "shap.summary_plot(svm_shap_values, xtest.iloc[0:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "oQURbHbCgV41"
   },
   "outputs": [],
   "source": [
    "# Summary of performance of all the models\n",
    "\n",
    "data_df = pd.DataFrame(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "pAc2liYIUygx",
    "outputId": "4ec6ce18-accd-4187-c61b-48fda3663a13"
   },
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "phxQiOkyia_r"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(model_outputs).to_csv(\"performance_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_SNGd2THjNaj",
    "outputId": "d7d4b294-7394-49f0-cd0d-c982ae00b17b"
   },
   "outputs": [],
   "source": [
    "%shell jupyter nbconvert --to html \"/content/MLModels_Confilict_Mean.ipynb\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Confilict_Mean - RemoveBurdens.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
